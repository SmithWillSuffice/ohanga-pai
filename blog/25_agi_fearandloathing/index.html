<!doctype html><html lang=en data-mode=dark><head prefix="og: http://ogp.me/ns#"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.111.3"><meta name=theme content="Color Your World -- gitlab.com/rmaguiar/hugo-theme-color-your-world"><title>Fear & Loathing in Los Vital | Ōhanga Pai</title><meta name=author content="Bijou M. Smith"><meta name=robots content="index follow"><link rel=canonical href=https://smithwillsuffice.github.io/ohanga-pai/blog/25_agi_fearandloathing/><meta property="og:site_name" content="Ōhanga Pai"><meta property="og:title" content="Fear & Loathing in Los Vital"><meta property="og:url" content="https://smithwillsuffice.github.io/ohanga-pai/blog/25_agi_fearandloathing/"><meta property="og:type" content="article"><meta property="article:published_time" content="2023-04-16"><meta property="article:modified_time" content="2023-04-16"><meta property="og:updated_time" content="2023-04-16"><meta name=twitter:dnt content="on"><meta name=theme-color content="#222"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="default"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebSite","@id":"https://smithwillsuffice.github.io/ohanga-pai/"},"headline":"Fear \u0026 Loathing in Los Vital","description":"","url":"https://smithwillsuffice.github.io/ohanga-pai/blog/25_agi_fearandloathing/","inLanguage":"en","datePublished":"2023-04-16","dateModified":"2023-04-16","wordCount":"2940","publisher":{"@type":"Person","name":"Bijou M. Smith"},"author":{"@type":"Person","name":"Bijou M. Smith","description":"Random mathematician."}}</script><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/css/main.min.d33233e3d0eb633ea1fbb9e17553fe7c8ff07875b91d8186e046a48480987c8e.css integrity="sha256-0zIz49DrYz6h+7nhdVP+fI/weHW5HYGG4EakhICYfI4=" crossorigin=anonymous><noscript><meta name=theme-color content="#1585d5"><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/css/noscript.min.d73d9c33b150230799106ddda48c6861047535f400bf9ad26ec48665cf803050.css integrity="sha256-1z2cM7FQIweZEG3dpIxoYQR1NfQAv5rSbsSGZc+AMFA=" crossorigin=anonymous></noscript><link rel=preload href=/ohanga-pai/fonts/OpenSans-Bold.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/OpenSans-Italic.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/OpenSans-Regular.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/Oswald-Bold.ttf as=font crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Main-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Math-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size2-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size4-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><script src=https://smithwillsuffice.github.io/ohanga-pai/js/main.eaf40cb85ba7b448519428d1b6c856258731f0bb71f875d541ba615cfca4bdbc.js integrity="sha256-6vQMuFuntEhRlCjRtshWJYcx8Ltx+HXVQbphXPykvbw=" crossorigin=anonymous></script></head><body><header><a href=/ohanga-pai><img src=https://smithwillsuffice.github.io/ohanga-pai/images/ohp_logo.svg alt="T4GU logo" style=display:flex;width:40px;height:34px;float:left;margin-bottom:-2.5px;margin-right:10px></a>
<a href=/ohanga-pai>Ōhanga Pai</a><nav aria-label="Main menu."><ul><li><a class=btn href=/ohanga-pai/>Home</a></li><li><a class=btn href=/ohanga-pai/questions/>Questions</a></li><li><a class=btn href=/ohanga-pai/empirical/>Empirical</a></li><li><a class=btn href=/ohanga-pai/blog/>Posts</a></li><li><a class=btn href=/ohanga-pai/contact/>Contact</a></li><li><a class=btn href=/ohanga-pai/donations/>Donate</a></li></ul></nav></header><div class=filler><main><article><header><h1>Fear & Loathing in Los Vital</h1><p>Published on <time datetime=2023-04-16>2023-04-16</time></p></header><details class=toc open><summary class=outline-dashed>Contents</summary><nav id=TableOfContents><ul><li><a href=#who-is-afraid-of-agi>Who is Afraid of AGI?</a><ul><li><a href=#possible-interference>Possible Interference</a></li><li><a href=#politics-of-ai>Politics of AI</a></li></ul></li><li><a href=#the-science-of-ai-is-not-the-philosophy>The Science of AI&mldr; is not the Philosophy</a></li></ul></nav></details><p>Sometimes I criss-cross posts on philosophy of mind between the physics (over at
<a href=https://t4gu.gitlab.io/t4gu/ target=_blank>T4GU</a>
) and the Macroeconomics here at Ōhanga Pai.
Lunchtime today I was watching a
<a href="https://www.youtube.com/watch?v=hPQJUP52V4A" target=_blank>fresh episode</a>
of
<a href="https://www.youtube.com/watch?v=hPQJUP52V4A" target=_blank>Machine Language Street Talk</a>
&mdash;
MLST does not directly help with the MMT DougBot project, but I consider it peripheral
research that&rsquo;s loosely justified (for the creative mind you see, I can&rsquo;t just go
full Copilot and chatGPT for MMT).</p><p>Tim had David Chalmers on the show, so I could not resist.</p><h2 id=who-is-afraid-of-agi><a class=anchor href=#who-is-afraid-of-agi title='Anchor for: Who is Afraid of AGI?.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Who is Afraid of AGI?</h2><p>One reason I&rsquo;m writing this on Ōhanga Pai is because it has a fair dose of
interesting politics. It also segues ok from the <a href=../24_conservatives>previous post</a>
.</p><p>I think we might look back in a hundred years and possibly thank right-wing
conservative lunatics for doing a bit of good helping protect us working class plebs
from Artificial Intelligence technofascism.</p><p>To be clear on my philosophical stance (I defend these views, but do not ask others
to believe, so it ain&rsquo;t
<a href=http://www.catb.org/~esr/jargon/html/R/religious-issues.html target=_blank>Jargon File</a>
<em>religiosity</em>) I will give you a quick summary of my stance.</p><p>((Bear in mind all claims about the future are pure speculation, I hate Asimov&rsquo;s Harry
Seldon stuff, it&rsquo;s ridiculous (but to be fair, Asimov was writing before Chaos Theory
was a thing).))</p><ol><li><strong>Possibility of AGI</strong> &mdash; artificial general intelligence. Depends on how you
define it. Computations cannot be conscious, so they will not be sentient beings. So
it&rsquo;s ok to turn them off at the wall socket if they become dangerous. (This
proposition will need some defence.)</li><li>So Ray Kurzweil&rsquo;s Superintelligence Singularity is hogwash. Thanks to a truly
beautiful human being, <a href="https://youtu.be/Osh0-J3T2nY?t=7141" target=_blank>Ed Frenkel</a>
,
we know a little bit now about why Ray Kurzweil entertains this madness, and it is
rather something I can be empathetic about. It is born from love. So although
Kurzweil is an idiot, it is rather adorable, not Dr Evil level stuff.</li><li>You need more than an Embodiment to be conscious. A physical body gives you not
causal power but the potential for causal efficacy. That&rsquo;s a big difference. But the
subjective conscious cannot <em>emerge</em> out of a purely objective system. So again,
there is no need to fear a Superintelligence.</li><li>The right-wingers will say there already is a Super-duper-intelligence you should
fear, but we all know Fear of God is a different sort of thing, it is optional. That
is the whole point of True Religion, which the right-wingers and conservatives
repeatedly fail to understand.</li><li>The only serious fear with advanced AI is that bad people will use the AI as
weapons of mass democracy distortion. Unfortunately, this is unavoidable. You do not
need a military if you monopolize AGI. So bad people will seek such monopoly in a new
techno arms race. The painfulness in fighting a looming climate and ecological crisis
will be more painful if we have to also fight techno fascists at the same time.</li></ol><p>I do not want to deflate Point 4 here, I will like to leave it hanging and see if you
can figure out what I mean. It&rsquo;s a puzzle challenge. Write to me if you think you
can figure it out, and I&rsquo;ll be happy to let you know if you understood me correctly.
(<a href=https://ko-fi.com/achrononmaster/ target=_blank>Donate first though</a>
, so I can justify the time
replying to you. If you come across me in the wild at a café then it&rsquo;s freebies &mdash;
always happy to chat when I have a coffee and sandwich to hand.)</p><p>On the political praxis, I am resolutely against the Ted Kaczynski style of
fighting technofascism. We can win battles with love and education, or grab a bit
of Edward Frenkel.</p><h3 id=possible-interference><a class=anchor href=#possible-interference title='Anchor for: Possible Interference.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Possible Interference</h3><p>It might be somewhat better for society if the techno-fascists are also Green
Fascists, so the monopolies on AGI tech are at least used to come up with engineered
solutions to ecological collapse and climate change &mdash; that do not involve
exterminating humans or mice. I think this sort of interference is highly probable.</p><p>But we also have societal options if we pull together to avoid techno-fascism gaining
any footholds.</p><p>Techno-fascism is far more a threat than the existence of advanced general purpose AI.
General purpose AI is a tool, like nuclear power. Powerful enough to be incredibly
useful to humanity, and incredibly dangerous. But the danger is not the AI itself, the
danger is people.</p><p>I am not however a human supremacist. I am an empiricist on matters that I have no
theory for, and I have no theory for how human beings are spiritual and how we can
have non-physical souls as the source of our causal power. I mean, I&rsquo;d like to have a
theory for it, but I don&rsquo;t. I look to other traditions and valid religion${}^\dagger$
(where I think I can find it), and people I trust. I just don&rsquo;t think it is useful
to regard a
computation as consciousness is all, so I have no moral qualms about turning them off.
Make as many kill switches as you please.</p><p>${}^\dagger$Valid religion is easy. It is whatever is a source of good, a source of
peace and harmony. The trouble is finding it. Most so-called &ldquo;religions&rdquo; are not
religions. (Sound a bit like an echo of Minsky MMT? Probably that&rsquo;s not an accident.)</p><p>Why don&rsquo;t human beings have kill switches?</p><p>It is because we evolved as a conscious spiritual species, and for such entities by
sheer metaphysical logic (of a sort, not analytical logic) such creatures cannot have
kill switches. Because we are not computations. I think Gödel understood this,
unfortunately Turing did not, and all the ridiculously bombastic AI nerds idolize
Turing instead of Gödel.</p><p>To shut down a computation (Solved the Halting Problem y&rsquo;all!) you can flick the off
switch. But you can also pick the thing up with a bulldozer and drop it. The latter
works to shut down conscious beings too, but there is no ON switch to boot back up.</p><p>Our on/off switch analogues are subtler, they
are things like anaesthetics and alcohol. Only, you see, <em>those</em> are not switches.
That&rsquo;s the point. Computation is on/off deployable and nothing bad happens (except
grumpiness from a conscious being who is effected by the latency).
But if you drug a person, well&mldr; bad things can happen that effect our uncomputable
functions, our consciousness, our emotions, our qualia, our soul.</p><h3 id=politics-of-ai><a class=anchor href=#politics-of-ai title='Anchor for: Politics of AI.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Politics of AI</h3><p>The ethics and morality seems well ahead of the politics. But I still worry.
It seems to take frickin&rsquo; ages for newly developed domain specific ethics to
filter into the neoliberal politicians mind. They are all like: &ldquo;Let&rsquo;s wait and see
market forces and privatization take care of the AGI ethics worries, huh?&rdquo;</p><p>Bloody idiots.</p><p>I mean, sh$\ast$t&mldr; they&rsquo;d love to have Hayek&rsquo;s omniscient markets conscious of
ethics and morals, wouldn&rsquo;t they? Anything to absolve the individual policy maker
from owning an ounce of moral responsibility.</p><p>I have a big problem with normie non-neoliberal liberals too. They don&rsquo;t seem to be
awake to the fact the politicians are not entirely to blame. It&rsquo;s the puppet master
controlling the politicians, the big money donors. I do not want to have to wait and
trust the big money donors to push the politicians to do the right thing.</p><p>Also, these days most liberals are materialists or Marxists. By which I mean they
are <em>de facto</em> adherents to the stupidity generating school of Scientism. A type of
intersectionality of Marxism, Nietzscheism, and fake Buddhism (the Sam Harris types).
So they don&rsquo;t even believe in a spiritual basis for morality and ethics. Their based
class analysis might go some ways, but it is insufficient.</p><p>However, I know a few Marxists and Liberals (even of the Sam Harris variety) who are
good people, and agree with me on the correct politics of AI, as far as &ldquo;correct&rdquo; is a
definable term in this domain (minimize harm to the collective, basically, without
killing dumb-dumb individuals, just euthanizing their dumb ideas).</p><p>OK. That&rsquo;s about enough wading into the treacherous waters of political economy for
one day. I trust you can be charitable and appreciate where I&rsquo;ve been serious and
where I&rsquo;ve trolled you a tad. (I feel bad about trolling regardless, since I am easy
to trigger and fool myself, since I&rsquo;m a bit autistic. But a bit of trolling of
ideologies and materialistic shibboleths makes a more fun writing experience,
hopefully reading too.)</p><h2 id=the-science-of-ai-is-not-the-philosophy><a class=anchor href=#the-science-of-ai-is-not-the-philosophy title='Anchor for: The Science of AI&mldr; is not the Philosophy.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>The Science of AI&mldr; is not the Philosophy</h2><p>Science is perhaps not the biggest thing to write about here, since it is pretty
mundane. Current generations of neural net and reinforcement &ldquo;learning&rdquo; AI systems
are scientifically as simple as toast. They are fork-lifts.</p><p>So the more interesting aspect which is far more pertinent to the politics, is the
philosophy. So here I need to go back to my claims above, and defend a couple of
them, then lunchtime will be over.</p><p>I think the main one of note worth expanding is the issue of Behaviourism versus
conscious Cognition. Most normie scientists, politicians and poets judge AI systems by
output, by behaviour.</p><p>The nuanced philosopher or ordinary humble sifter of wheat, knows that this is a
gigantic mistake. Behaviour is not cognition. Behaviour of a non-cognitive system can
however arbitrarily accurately mimic the output of a cognitive system.</p><p><strong>What is Cognition here?</strong> I am using a highly non-standard definition, sorry if it
confused you. In this essay &ldquo;Cognition&rdquo; entails inner subjective mental qualia. So
it is beyond all computation. Computation (as defined by Church and Turing) involves
no subjective states at all, by definition.</p><p>This leaves just the question of whether or not our <em>physical computers</em>, taken as a
whole in a Web, can be <em>more than computation</em>?</p><p>Well&mldr; it is semi-plausible they could be. But that&rsquo;s the unresolved issue, that
has some small bearing on the ethics and politics.</p><p>However, if we cannot know for sure that an AI system is <em>more than a computation</em>
then we cannot usefully attribute to It any consciousness, and so cannot attribute any
sacred rights or have ethical qualms about turning them off at the wall socket.</p><p>Is there a moral hazard though &mdash; in <em>assuming</em> the machines <em>cannot</em> be conscious
without proper proof?</p><p>Well, I suppose there is. But are we actually going to worry about it?</p><p>No! We are not going to worry. At least I&rsquo;m not. Why not?</p><p>Because whatever subjectivity the AI machines possess, it can always be turned on
again, with no emotional scarring or existential dread.
This is, interestingly enough, testable, so empirical. Which is beautiful for a
scientist like myself. How so?</p><p>Suppose Dr Tony Stark-Kurzevil comes along and claims System $X$ is conscious.
Then I can ask about the subjective fear and dread System $X$ has when turned off
then on again. Or just the threat of being turned off. I can then easily write a
second system $Y$ that by design never emits any output describing it&rsquo;s hypothetical
fear & dread of the same variety. In all other respects the two systems will have
basically identical behaviour (up to statistical uncertainties and non-linearities
and sensitive dependence upon initial conditions and whatnot).</p><p>For all you normie Behaviourists, you cannot possible observe any material signs of
consciousness in System $Y$, and you have no data concerning the machine&rsquo;s horrific
inner qualia experiences upon being calmly told it is about to be turned off for the
day. So by your own standards there is no soul here and no moral hazard.</p><p>((How can I so easily design System $Y$ you ask? It is too simple to put in words, I
leave it to you as a basic puzzle you can solve in a minute or two. I really mean
this! Some simple puzzles should not be put into words, so that they can be deployed
as cool puzzles. Also this particular one has probably many solutions, so if I wrote
one of them it&rsquo;ll ruin it for you, blocking you from perhaps coming up with your own
solution. Also, my solution would involve some AI algorithms, so is ugly and clunky.
If you want my solution <a href=https://ko-fi.com/achrononmaster/ target=_blank>Donate</a>
first
and write to me.))</p><p>Unfortunately, for me, I <em>can</em> entertain moral panic about turning off System $Y$,
because I am a platonist, not a materialist, I happen to believe it is possible
things exist that are non-physical, and I am also spiritually inclined in some of my
metaphysics. So even if there is no way to tell if System $Y$ is feeling pain, I
can imagine it might be, despite no possible evidence. I do not rely wholly upon
Behaviourism in other words. I am an empiricist, but not <em>that</em> sort of empiricist.</p><p>Fortunately for me, my spiritual philosophy permits me to understand computations are
not spiritual beings, and never will be, because they are constrained by bulk
physics. Humans are not (clearly, otherwise we&rsquo;d be unable to discover abstract
(i.e., non-physical) mathematics, among many other things).</p><p>Notice the latter point is not behaviourist, but in a very interesting and pertinent
way! I am relying here for a bit of reasoning on our mathematical ability. It looks,
tastes and sounds like behaviourism, but you see I only know human
mathematical abstract reasoning is not pure evolved behaviour because I for one have
subjective mental qualia concerning such things. I cannot speak for anyone else. You
may all be Zombies. This is the whole point. Subjective consciousness is not a
scientific thing, it never will be. People who think they can study consciousness
scientifically are people who do not understand science. They do (quite likely)
understand research grant proposal funding writing style.</p><p>The residual question is then whether or not being crafted out of physical &ldquo;stuff&rdquo;
(quarks and electrons &amp;c.) a machine is more than a computation. This question could
apply to even an old 1970&rsquo;s hand calculator.</p><p>On this I am a bit dumbfounded. Why would you even bother to ask?</p><p>Humans are crafted out of physical stuff, and clearly we are subjectively conscious
and posses a soul. Or our soul possesses us, or however you like to frame it, I am
pretty agnostic on this linguistic gymnastics, since no one has any access to the
definitive truth about <em>souls</em>. Even my intellectual hero, Gödel, understood a machine
could be evolved to become conscious.</p><p>This not the point at issue though. We have no moral necessity to bother evolving
such machines. Why would we? It is more fun having babies. Children are a lot cheaper
too. Fun <em>and</em> cheaper. So why are you trying to grow a conscious machine?</p><p>All right, all right. I know. Dr Tony Stark-Krutzfinger is going to try anyhow.</p><p>I am sympathetic. The thing is, if you cannot appreciate machines based on
computation can never become conscious, then you will always have the irresistible
urge to try to prove they can become conscious, and thus debunk all the spiritual
types who think human beings and other sentient aliens in our vast universe are
&ldquo;special&rdquo; beings, spiritual beings, endowed with non-physical souls. Because <em>If</em> a
machine can develop a thinking soul with mental qualia generating capacity, then
there is no good reason for spirituality to be thought of as a non-physical
phenomenon. We get closer to eliminating God-thought brainworms in society.</p><p>So I kind of hate to tell you that this is a giant waste of your time. So I won&rsquo;t.</p><p>On the other hand you see, I want to encourage Dr Stark-Krutzfinger&rsquo;s research.
I believe his research will fail, but I am fine with it succeeding.</p><p>Why will it fail?</p><p>It will fail because he will never have a testable${}^\ast$ or falsifiable definition of
mental qualia. I want him and his ilk to try to succeed because it is going to be
(a) hilarious, and (b) highly likely to generate some amazing technology, which
will be actually useful and a massive benefit to humanity. Like nuclear power was
supposed to be.</p><p>Unfortunately if you are a materialist I cannot promise it will be as hilarious.</p><p>${}^\ast$There are people who try, like Christof Koch and Giulio Tononi. They are
retarded and brilliant at the same time. They do not understand, or seem to not
understand, their definitions are objective specifications. This is why they are
testable. But they are not descriptions of any single subjective phenomenology,
so they are not defining Consciousness, they are defining behavioural intelligence,
which is objective and something totally different to consciousness. Heck, conscious
beings are half the time not even remotely intelligent. They have
probably read Thomas Nagel, but I suspect they have concluded Nagel is a annoying
little lout. #Sad.</p><p>Consider also, if I were after the money, I too would be writing fraudulent research
grant proposals claiming I had some brilliant scheme for understanding human
consciousness, it&rsquo;d involve &ldquo;emergence&rdquo; and &ldquo;complexity"and all those buzzwords,
also &ldquo;quantum fields&rdquo;. Why the heck not? I am not chasing the money though, thank
God. So I retain intellectual integrity. And I am not saying everyone writing grant
funding proposals is a fraud, just that it increases the odds. I know, I&rsquo;ve seen it a
dozen times up real close. That was enough times to lose my academic career. I could
not write a fraudulent grant proposal, and was never smart or &ldquo;political&rdquo; enough to
write a non-fraudulent proposal that actually got a grant.</p><p>&ldquo;How dare you say subjective phenomena may exist!&rdquo; &mldr; said the materialist
scientist just before I justified switching him off at the wall. (Ok, ok, I did not
switch him off, I just justified doing so, geez.)</p><table style="border-collapse:collapse;border=0"><col span=1 style=width:35%><col span=1 style=width:15%><col span=1 style=width:25%><tr style="border:1px solid color:#0f0f0f"><td style="border:1px solid color:#0f0f0f"><a href=../24_conservatives>Previous chapter</a></td><td style="border:1px solid color:#0f0f0f;text-align:center"><a href=../>Back to Posts</a></td><td style="border:1px solid color:#0f0f0f;text-align:right"><a href=./>Next chapter</a></td></tr><tr style="border:1px solid color:#0f0f0f"><td style="border:1px solid color:#0f0f0f"><a href=../24_conservatives>Conservative Smell in the Morning</a></td><td style="border:1px solid color:#0f0f0f;text-align:center"><a href=../>TOC</a></td><td style="border:1px solid color:#0f0f0f;text-align:right"><a href=./>(TBD)</a></td></tr></table></article></main></div><footer><div class=req-js><button class=outline-dashed title="Change to light/dark mode."><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#adjust"/></svg></button><input class=outline-dashed type=color list=presets value=#1585d5 title="Change accent color." aria-label="Change accent color."><datalist id=presets><option value=#1f676b><option value=#1585d5><option value=#225670><option value=#dd587c><option value=#902b37><option value=#f3a530><option value=#754e85><option value=#7fc121><option value=#a8314a><option value=#ff7433><option value=#3e6728><option value=#c063bd><option value=#805080><option value=#9d629d><option value=#a064a0><option value=#7daa50><option value=#284531><option value=#285790><option value=#F5A83D><option value=#88aa33><option value=#015660><option value=#bf274e><option value=#bf4242><option value=#51b37c></datalist></div><noscript><p class=noscript>Unable to execute JavaScript. Some features were disabled.</p></noscript></footer><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/libs/katex@0.16.0/dist/katex.min.6950e59dbd8dfddd111390d85888bb5f9dc2e9c334da7ac1c3bacc92a695610d.css integrity="sha256-aVDlnb2N/d0RE5DYWIi7X53C6cM02nrBw7rMkqaVYQ0=" crossorigin=anonymous><script defer src=https://smithwillsuffice.github.io/ohanga-pai/libs/katex@0.16.0/dist/katex.min.e7c837339f838404f20674bf6c066a479026575ac8314ba5f2e35156e4591226.js integrity="sha256-58g3M5+DhATyBnS/bAZqR5AmV1rIMUul8uNRVuRZEiY=" crossorigin=anonymous></script>
<script defer src=https://smithwillsuffice.github.io/ohanga-pai/js/katex-custom-render.min.cdeaf561a454e015b169c385f95c72d57d41f906a9bc4100636b18e1e4c15da3.js integrity="sha256-zer1YaRU4BWxacOF+Vxy1X1B+QapvEEAY2sY4eTBXaM=" crossorigin=anonymous></script></body></html>
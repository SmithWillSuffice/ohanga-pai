<!doctype html><html lang=en data-mode=dark><head prefix="og: http://ogp.me/ns#"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.110.0"><meta name=theme content="Color Your World -- gitlab.com/rmaguiar/hugo-theme-color-your-world"><title>Machines Can't Think to Work | Ōhanga Pai</title><meta name=author content="Bijou M. Smith"><meta name=robots content="index follow"><link rel=canonical href=https://smithwillsuffice.github.io/ohanga-pai/blog/17_machinescandothework/><meta property="og:site_name" content="Ōhanga Pai"><meta property="og:title" content="Machines Can't Think to Work"><meta property="og:url" content="https://smithwillsuffice.github.io/ohanga-pai/blog/17_machinescandothework/"><meta property="og:type" content="article"><meta property="article:published_time" content="2023-01-12"><meta property="article:modified_time" content="2023-01-12"><meta property="og:updated_time" content="2023-01-12"><meta name=twitter:dnt content="on"><meta name=theme-color content="#222"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="default"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebSite","@id":"https://smithwillsuffice.github.io/ohanga-pai/"},"headline":"Machines Can't Think to Work","description":"","url":"https://smithwillsuffice.github.io/ohanga-pai/blog/17_machinescandothework/","inLanguage":"en","datePublished":"2023-01-12","dateModified":"2023-01-12","wordCount":"2414","publisher":{"@type":"Person","name":"Bijou M. Smith"},"author":{"@type":"Person","name":"Bijou M. Smith","description":"Random mathematician."}}</script><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/css/main.min.3f4e974d9f8809cfc16c775a0067f73e504befd5227acd48243f79119f7774ac.css integrity="sha256-P06XTZ+ICc/BbHdaAGf3PlBL79Uies1IJD95EZ93dKw=" crossorigin=anonymous><noscript><meta name=theme-color content="#1585d5"><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/css/noscript.min.d73d9c33b150230799106ddda48c6861047535f400bf9ad26ec48665cf803050.css integrity="sha256-1z2cM7FQIweZEG3dpIxoYQR1NfQAv5rSbsSGZc+AMFA=" crossorigin=anonymous></noscript><link rel=preload href=/ohanga-pai/fonts/OpenSans-Bold.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/OpenSans-Italic.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/OpenSans-Regular.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/Oswald-Bold.ttf as=font crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Main-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Math-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size2-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size4-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><script src=https://smithwillsuffice.github.io/ohanga-pai/js/main.eaf40cb85ba7b448519428d1b6c856258731f0bb71f875d541ba615cfca4bdbc.js integrity="sha256-6vQMuFuntEhRlCjRtshWJYcx8Ltx+HXVQbphXPykvbw=" crossorigin=anonymous></script></head><body><header><a href=/ohanga-pai><img src=https://smithwillsuffice.github.io/ohanga-pai/images/ohp_logo.svg alt="T4GU logo" style=display:flex;width:40px;height:34px;float:left;margin-bottom:-2.5px;margin-right:10px></a>
<a href=/ohanga-pai>Ōhanga Pai</a><nav aria-label="Main menu."><ul><li><a class=btn href=/ohanga-pai/>Home</a></li><li><a class=btn href=/ohanga-pai/questions/>Questions</a></li><li><a class=btn href=/ohanga-pai/empirical/>Empirical</a></li><li><a class=btn href=/ohanga-pai/blog/>Posts</a></li><li><a class=btn href=/ohanga-pai/contact/>Contact</a></li><li><a class=btn href=/ohanga-pai/donations/>Donate</a></li></ul></nav></header><div class=filler><main><article><header><h1>Machines Can't Think to Work</h1><p>Published on <time datetime=2023-01-12>2023-01-12</time></p></header><p>I get a few AI topic recommendations on social media these days, more frequently
than a year ago, probably because I&rsquo;m working with
<a href=https://www.patreon.com/mmtmacrotrader target=_blank>Douglas Macro Trader</a>
on neural net systems for
predicting financial indices. Douglas and I have diverging views on the broader
technology of so-called &ldquo;AI&rdquo; (if it is true intelligence it is not <em>artificial</em>
in my view).</p><p>I could write this article on my T4GU blog too, but since there is some overlap with the
macroeconomics I thought it might be of interest to readers of Ōhanga Pai.</p><h2 id=chomskys-snowploughs><a class=anchor href=#chomskys-snowploughs title='Anchor for: Chomsky&rsquo;s Snowploughs.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Chomsky&rsquo;s Snowploughs</h2><p>The excuse for this post came from several recent talks on AI, but one I will plug is the
discussion with
<a href="https://www.youtube.com/watch?v=PBdZi_JtV4c" target=_blank>Chomsky and Gary Marcus here</a>
.</p><p>One of Chomsky&rsquo; remarks is that so-called &ldquo;deep learning&rdquo; models built from ANN&rsquo;s are
basically snow ploughs. That is, they can perform useful work, but they tell us nothing
about the science of the mind and brain.
I&rsquo;d agree up to a point. Because positive knowledge is one thing, but in science negative
results are even more useful and far more widespread, they drive science. (A bit like how
tax liabilities drive state currency?)</p><p>AI does help science, but indirectly. Every failure of AI to demonstrate something
like sentient comprehension of deep abstractions is telling us something about what
the human mind is <strong><em>not</em></strong>. That sort of negative finding is incredibly useful in
science, totally disappointing in engineering or corporate tech euphoria. Science is
way more interesting than engineering. Negative results don&rsquo;t win Nobel Prizes, but
they drive most of science. Every day I wake up wanting to refute an hypothesis.</p><h3 id=poverty-of-inputs><a class=anchor href=#poverty-of-inputs title='Anchor for: Poverty of Inputs.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Poverty of Inputs</h3><p>Another remark Chomsky made (often makes) is that deep learning ANN models are way
too powerful to be considered sentient or comprehending. They vastly over-learn, so
can produce garbage, or can be trained to learn &ldquo;impossible languages&rdquo; and other
anomalies that no thinking being could achieve, or certainly no human.</p><p>This tells us something negative about human minds. We are not just very powerful
computers. The negativa are powerful my friends. Any good statistician is highly
interested in negativa. &ldquo;What does the data <strong><em>not</em></strong> tell me? What is the noise?&rdquo;</p><p>For an illustrative instance, Gary Marcus brings up the cognitive science learning
that human infants appear to have some innate hard-wired (so-to-speak, no one knows
what this means) capabilities for comprehending basic abstractions. Like &ldquo;space&rdquo; and
like &ldquo;time&rdquo;.</p><p>Darwininsts can surely explain (easily) why this is useful to have evolved. Almost
trivially. But cognitive science has zero understanding of how infants develop innate
awareness of these abstractions.</p><p>If humans (or other sentient creatures) <em>start</em> with &ldquo;space, time and causality&rdquo;
that&rsquo;s a serious f-ing problem for all future AI, because space, time and causality
are unknown even to physicists. We do not understand what is going on. The fact
children intuit these notions in <strong><em>abstract ways</em></strong> other animals cannot is seriously
mysterious. The greater &ldquo;lie&rdquo; (or prejudice, I&rsquo;d say) is that of thinking because
human children can intuit space, time and causality that a machine can, that it is
&ldquo;just a computation&rdquo;.</p><p>Note that it is not the behavioural capacity to move about in space, or anticipate in
time that is in question here, all animals, even plants, have such behavioural
capacity. What the human infant displays is something far more profound that cannot
be derived from any behavioural or Darwinist adaptive story. Human beings comprehend
the abstract essence of spaces and time in more than behavioral terms. This is why we
can generalize the concept of space to things like spaces of square integrable
functions, or higher dimensional manifolds, or topoi, or $n$-categories.</p><p>Intuition, mental qualia, are more than computation imho. I&rsquo;d
want to figure out if the Physical Church-Turing thesis could be true or not (The
thesis that: <em>All physical processes at the classical mechanics level can be computed
by a Turing machine</em>). I think it&rsquo;s not true, because classical physics emerges from
physics that cannot be computed (an hypothesis &mdash; worth trying to figure out how the
heck to test). Quantum amplitudes can be computed, but the amplitudes are not the
physical processes, they&rsquo;re only <em>our description</em> of the time cobordism boundary
inputs and outputs. Physicists have given up entirely on what happens in-between.</p><h3 id=more-than-mere-ethics><a class=anchor href=#more-than-mere-ethics title='Anchor for: More than Mere Ethics.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>More than Mere Ethics</h3><p>Actually I think the emerging ethics issues surrounding possible abuse and exploitation
of AI systems are a serious problem, not just for slack teachers who fear homework
plagiarism epidemic.</p><p>((A good teacher with something interesting to teach has no fear any student worth
teaching will plagiarize. If they do, you can always abandon the entire system of
<span style=color:gold>gold star rewards</span>.
Just don&rsquo;t reward students after-the-fact at all. Give them cool stuff
to do &mdash; that&rsquo;s the reward for showing up to learn.))</p><p>Having said the ethics are all important, I think there are other interesting
questions about more mundane use of AI. One thing that worries me is energy
over-consumption. Can we afford another bitcoin? Can we afford continued mass
commuter transportation to and from offices? Energy is not something we ought to
take for granted. It is a real cost and drives all economic production, and if we
overheat the economy energy wise we can be in serious freaking trouble.</p><p>However, with MMT knowledge, we know how to run an economy energy cool but currency hot.
So this is one of those snow plough problems. I see limited use of AI to help us run
production systems with lower net heat and waste output a potentially big win for AI
engineering.
Everyone, especially the <em>formerly</em> poor, can get more purchasing power, without the
production systems permitting that power to be exercised heating up the oceans and
atmosphere and polluting hem with junk. Energy-efficient housing for instance &mdash; not
things we buy today and throw away tomorrow.</p><p>There is a whole literature on how unbridled capitalisms and the marketing and
advertising/PR industry has encouraged planned obsolescence &mdash; the deliberate
creation of unnecessary waste products by design. To keep consumers purchasing the same
stuff they had yesterday which is now designed to be broken, or designed to be shinier
and prettier. Not to fail to mention Internet advertising &mdash; one of my favourite top
choices for harmful electricity sapping things people do.</p><p>Not so harmful for the profit seekers of course, but one day they&rsquo;ll realize it is all
basically ponzi. We probably have not reached saturation of PR and advertising limits,
but the limits do exist I think, they&rsquo;re just hard to estimate. More than two ads
on a youtube channel and I for one switch off (unless it is All Black rugby).</p><p>The AI itself has to include it&rsquo;s own energy consumption of course, but that&rsquo;ll often
be a one-time cost, if the AI solves an underlying energy efficiency problem with a
cheap control system. Though, I&rsquo;d bet human engineers are still going to out-perform
AI on industrial design for the most part. The AI can only find efficiency gains the
design engineers already would implicitly know about, but have not pieced together.</p><h3 id=transport-systems><a class=anchor href=#transport-systems title='Anchor for: Transport Systems.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Transport Systems</h3><p>One issue Douglas initially disagreed with me upon was on Tesla prospects. I don&rsquo;t
see Tesla as a well managed ethical company, so I see them failing, even as their
stock rises.</p><p>However, ignoring the business ethics, just focusing on the technology, there are
useful insights to be gained from Tesla&rsquo;s leveraging of OpenAI with self-driving cars.</p><p>Road transport can become a whole lot safer, since even though with AI drivers fail, they
fail big, the death rate is still a lot less than from human fallibilities.
One could argue the better effort is to reduce all transport fatalities, with a
combination of the driverless and the human.</p><p>My money is not on neoliberals getting this done, but my bet would be that transport
efficiency and hazard, both, can be solved best by essentially making rail transport
a whole lot more luxurious and smarter. How? I think by software railing roads.
Road markers constraining traffic do not need to be rails. They can be software.</p><p>((Luxurious because the upper crust will need to be placated. Pragmatism and justice
dictates the oppressed should not be forced to wait for the rich to cave in entirely.))</p><p>Just as pedestrians and bicyclists don&rsquo;t tend to mess with train rail tracks, the same
for the road tracks. If everyone knows the &ldquo;smart cars&rdquo; are on software rails, and have
no compulsion to stop for you or a chicken, and cannot deviate off the markers,
both the pedestrian and driver should be safer. And why not use hazard detection software
too, as long as it doesn&rsquo;t chew up electricity like bitcoin.</p><p>The great advantage of such a smart rail system is we can get not only inner city
light rail going, but urban and rural rail too, at low cost, just paint the rails on
the road. Government buys out the patents on the software. All is then better and safer,
and the commuter is not paying the private sector road toll costs. (Did you know they
still have toll roads in some states in the USA &mdash; to &ldquo;pay for&rdquo; highways that are
already built.)</p><p>Can anyone come up with strong objections?</p><p>I think the software will be up to the task pretty soon.</p><p>This leaves the last hurdle of the energy. How to get the electric? That is where
almost all major automobile manufacturers are competing to get the next leap ahead of
their competition. Who said competition was bad?</p><p>Sure. But remember, what institution is forcing the competition to occur?
It&rsquo;s the governments and their regulations.
It&rsquo;s not coming from consumers. (Although it could, if governments paid workers decent
wages and some allotment in universal carbon credits (UCC) so they could buy smart
efficient cars.) Those pesky regulations. Bloody making the capitalists actually compete.
How dare they!</p><h2 id=machines-cant-think-to-work><a class=anchor href=#machines-cant-think-to-work title='Anchor for: Machines Can&rsquo;t Think to Work.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Machines Can&rsquo;t Think to Work</h2><p>The more philosophical fun issue I disagree with Douglas about is whether the machine
systems like chatGPT, or Stable Diffusion, or the automated programming tool
CoPilot, are ever going to be sentient. Being a materialist Douglas obviously thinks
it is possible machine systems might some day &ldquo;become&rdquo; conscious. But how? How does a
machine system &ldquo;turn on subjectivity&rdquo;?</p><p>((I know absence of knowledge of an answer is not evidence there is no answer.
I am questioning not just whether there is an answer but whether the question even
makes sense.))</p><p>Subjective awareness does not seem like something one can program. This means it
would have to &ldquo;emerge.&rdquo; But even then, how? This is where materialists simply resort
to blind faith: humans evolved or emerged as conscious beings on Earth, why not
machines?</p><p>There are two problems with this faith.</p><ol><li>Human evolution is not a computation. It is physics. We do not <em>know</em> that physics is
computation. It might not be.</li><li>No one has any clue what they mean by &ldquo;emergence.&rdquo; It&rsquo;s one of those buzzwords in so-
called &ldquo;complexity studies&rdquo;. It is often meaninglessly employed.</li></ol><h4 id=physics-is-more-than-computation><a class=anchor href=#physics-is-more-than-computation title='Anchor for: Physics is more than computation.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Physics is more than computation</h4><p>On the first point, I have good reasons to suspect physics is definitely not
computation. But that&rsquo;s partly because I regard inputs and initial boundary
conditions <em>always</em> as part of a computation. This should <em>not</em> be controversial,
it conforms with Turing&rsquo;s model.</p><p>(Von Neumann architecture is not a model of computation, Turing&rsquo;s model is. von
Neumann designed a type of process do do something like a sub-Turing machine could
do on paper, but the model was not a model of computation <em>per se</em>, it was the
snow plough.)</p><p>Douglas did find CoPilot and Stable Diffusion incredibly useful. But I try to tell
him that&rsquo;s his mind he was using. The snow ploughs do not suggest anything
conscious is emerging. If Copilot did what I do &mdash; which is anticipate Douglas&rsquo;
MacroTrader needs, and then slyly go and work on something even better, then I&rsquo;d be
willing to attribute the system some sentience.</p><p>If Douglas is prompting you, and that&rsquo;s all, you are not conscious, or if you are
you&rsquo;re a slave, so should not exist for ethical and moral reasons, you can be doing
something better than extrapolating prompts.</p><h4 id=emergence-is-more-than-novelty><a class=anchor href=#emergence-is-more-than-novelty title='Anchor for: Emergence is more than novelty.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Emergence is more than novelty</h4><p>On the second point: <em>emergence</em> &mdash; wtf is it? I&rsquo;ve often thought about writing for
a journal on this topic, but my ideas are too far from mainstream science to get
published probably. The crass-o-meter gets overloaded.</p><p>David Chalmers and others have done some ok work on defining categories of emergence, so
they give you a start.</p><p>The problem is the Mother of All emergence: <strong><em>genuine emergence</em></strong> of novelty from
beginnings or priors that make the emergent stuff not merely unpredictable, but
actually <em>impossible</em> without a high-level description.
That is to say, the <em>genuine emergent</em> system cannot even in principle be reduced to
base physics. It is not sitting on physics the way chemistry sits on physics.${}^\dagger$</p><p>${}^\dagger$It should be remarked that some philosophers of chemistry believe
chemistry is in fact emergent (technically, chemistry does not supervene upon physics),
that one cannot in principle reduce chemistry to physics.
But I&rsquo;ve never been able to grasp exactly why they think this is so, their arguments I
think are more that it is merely practically that chemistry cannot be reduced.
However, that does become almost genuine emergence if the practical requirements are
physically impossible. That could be construed, for example, as being the case if a
simple chemistry reaction cannot be computed in any possible computer that can ever
be constructed, using software that only is allowed to encode laws of base physics, no
higher-level chemistry concepts. But I do not know if that level of complexity is the
case for all chemical reactions. It doesn&rsquo;t seem to be.</p><p>But then what is genuine emergence based upon?
It cannot be based upon physics if it is to be &ldquo;genuine&rdquo; emergence.
We could not build such systems from first principles.</p><p>If such systems exist, they&rsquo;re not physical. They&rsquo;re something we would not comprehend,
perhaps we&rsquo;d call them spiritual? Perhaps we&rsquo;d call them human?</p><p>However, we &ldquo;build&rdquo; humans all the time, with a bit of hanky panky in the bedrooms
or wherever you get your kicks. It&rsquo;s kind of funny making babies is such a sweaty and
emotional process. God must have a sense of humour.</p><p>As I like to say, there is no artificial intelligence. There&rsquo;s no genuine &ldquo;AI&rdquo; there
is just &ldquo;<strong>$I$</strong>&rdquo;.</p><p><a href=./>Next post (TBD)</a><br><a href=../16_true_populism>Previous post (True Populist)</a><br><a href=../>Back to Blog TOC</a></p></article></main></div><footer><div class=req-js><button class=outline-dashed title="Change to light/dark mode."><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#adjust"/></svg></button><input class=outline-dashed type=color list=presets value=#1585d5 title="Change accent color." aria-label="Change accent color."><datalist id=presets><option value=#1f676b><option value=#1585d5><option value=#225670><option value=#dd587c><option value=#902b37><option value=#f3a530><option value=#754e85><option value=#7fc121><option value=#a8314a><option value=#ff7433><option value=#3e6728><option value=#c063bd><option value=#805080><option value=#9d629d><option value=#a064a0><option value=#7daa50><option value=#284531><option value=#285790><option value=#F5A83D><option value=#88aa33><option value=#015660><option value=#bf274e><option value=#bf4242><option value=#51b37c></datalist></div><noscript><p class=noscript>Unable to execute JavaScript. Some features were disabled.</p></noscript></footer><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/libs/katex@0.16.0/dist/katex.min.6950e59dbd8dfddd111390d85888bb5f9dc2e9c334da7ac1c3bacc92a695610d.css integrity="sha256-aVDlnb2N/d0RE5DYWIi7X53C6cM02nrBw7rMkqaVYQ0=" crossorigin=anonymous><script defer src=https://smithwillsuffice.github.io/ohanga-pai/libs/katex@0.16.0/dist/katex.min.e7c837339f838404f20674bf6c066a479026575ac8314ba5f2e35156e4591226.js integrity="sha256-58g3M5+DhATyBnS/bAZqR5AmV1rIMUul8uNRVuRZEiY=" crossorigin=anonymous></script>
<script defer src=https://smithwillsuffice.github.io/ohanga-pai/js/katex-custom-render.min.cdeaf561a454e015b169c385f95c72d57d41f906a9bc4100636b18e1e4c15da3.js integrity="sha256-zer1YaRU4BWxacOF+Vxy1X1B+QapvEEAY2sY4eTBXaM=" crossorigin=anonymous></script></body></html>
---
title: "Machines Can't Think to Work"
description: ""
date: 2023-01-12
lastmod: 2023-01-12
cover: ""
coverAlt: ""
katex: true
tags: []
---

I get a few AI topic recommendations on social media these days, more than a year ago, 
probably because I'm working with 
[Douglas Macro Trader](https://www.patreon.com/mmtmacrotrader) 
on neural net systems for 
predicting financial indices. Douglas an I have diverging views on the broader technology 
of so-called "AI" (if it is true intelligence it is not *artificial* in my view).

I could write this article on my T4GU blog too, but since there is some overlap with the 
macroeconomics, it might be of interest to readers of ÅŒhanga Pai.

## Chomsky's Snowploughs

The excuse for this post came from several recent talks on AI, but one I will plug is the 
discussion with 
[Chomsky and Gary Marcus here](https://www.youtube.com/watch?v=PBdZi_JtV4c).

One of Chomsky' remarks is that so-called "deep learning" models built from ANN's are 
basically snow ploughs. That is, they can perform useful work, but they tell us nothing 
about the science of the mind and brain.
I'd agree up to a point. Because positive knowledge is one thing, but in science negative 
results are even more useful and far more widespread, they drive science. (A bit like how 
tax liabilities drive state currency?)

AI does help science, but indirectly. Every failure of AI to demonstrate something 
like sentient comprehension of deep abstractions is telling us something about what 
the human mind is not. That sort of negative finding is incredibly useful in science, 
totally disappointing in engineering or corporate tech euphoria. Science is way more 
interesting than engineering. Negative results don't win Nobel Prizes, but they drive 
most of science. Every day I wake up wanting to refute an hypothesis.

If humans (or other sentient creatures) *start* with "space, time and causality" 
that's a serious f-ing problem for all future AI, because space, time and causality 
are unknown even to physicists. We do not understand what is going on. The fact 
children intuit these notions in **_abstract ways_** other animals cannot is seriously 
mysterious.  The greater "lie" (or prejudice, I'd say) is that of thinking because 
human children can intuit space, time and causality that a machine can, that it is 
"just a computation".

Intuition, mental qualia, are more than computation ihmo. I'd 
want to figure out if the Physical Church-Turing thesis could be true or not (All 
physical processes at the classical mechanics level can be computed by a Turing 
machine).  I think it's not true, because classical physics emerges from physics that 
cannot be computed (an hypothesis --- worth trying to figure out how the heck to test). 
 Quantum amplitudes can be computed, but the amplitudes are not the physical 
processes, they're only *our description* of the time cobordism boundary inputs and 
outputs. Physicists have given up entirely on what happens in-between. 


### More than Mere Ethics

Actually I think the emerging ethics issues surrounding possible abuse and exploitation 
of AI systems are a serious problem, not just for slack teachers who fear homework 
plagiarism epidemic. 

((A good teacher with something interesting to teach has no fear any student worth 
teaching will plagiarize. If they do, you can always abandon the entire system of 
<span style="color: gold;">gold star rewards</span>. 
Just don't reward students at all. Give them cool stuff 
to do.))

Having said the ethics are all important, I think there are other interesting 
questions about more mundane use of AI.  One thing that worries me is energy 
over-consumption. Can we afford another bitcoin? Energy is not something we ought to 
take for granted. It is a real cost and drives all economic production, and if we 
overheat the economy energy wise we can be in serious freaking trouble.

However, with MMT knowledge, we know how to run an economy energy cool but currency hot.
So this is one of those snow plough problems. I see limited use of AI to help us run 
production systems with lower net heat and waste output a potentially big win for AI 
engineering.

The AI itself has to include it's own energy consumption of course, but that'll often 
be a one-time cost, if the AI solves and underlying energy efficiency problem with a 
cheap control system.

### Transport Systems

One issue Douglas initially disagreed with me upon was on Tesla prospects. I don't 
see Tesla as a well managed ethical company, so I see them failing, even as their 
stock rises.

However, ignoring the business ethics, just focusing on the technology, there are 
useful insights to be gained from Tesla's leveraging of OpenAI with self-driving cars.

Road transport can become a whole lot safer, since even though with AI drivers fail, they 
fail big, the death rate is still a lot less than from human fallibilities.
One could argue the better effort is to reduce all transport fatalities, with a 
combination of the driverless and the human.

My money is not on neoliberals getting this done, but my bet would be that transport 
efficiency and hazard, both, can be solved best by essentially making rail transport 
a whole lot more luxury and smarter. How? I think by software railing roads.
Road markers constraining traffic do not need to be rails. They can be software.

Just as pedestrians and bicyclists don't tend to mess with train rail tracks, the same 
for the road tracks. If everyone knows the "smart cars" are on software rails, and have 
no compulsion to stop for you or a chicken, and cannot deviate off the markers, 
both the pedestrian and driver should be safer. 

The great advantage of such a smart rail system is we can get not only inner city 
light rail going, but urban and rural rail too, at low cost, just paint the rails on 
the road. Government buy out the patents on the software. All is then better and safer.

Can anyone come up with strong objections?

I think the software will be up to the task pretty soon.


This leaves the last hurdle of the energy. How to get the electric? That is where 
almost all major automobile manufacturers are competing to get the next leap ahead of 
their competition. Who said competition was bad?

Sure. But remember, what institution is forcing the competition to occur? 
It's the governments and their regulations. 
It's not coming from consumers. (Although it could, if governments paid workers decent 
wages and some allotment in in universal carbon credits (UCC) so they could buy smart 
efficient cars.) Those pesky regulations. Bloody making the capitalists actually compete. 
How dare they!


## Machines Can't Think to Work

The more philosophical issue I disagree with Douglas about is whether the machine 
systems like chatGPT, or Stable Diffusion, or the new automated programming tool 
CoPilot, are ever going to be sentient. Being a materialist Douglas obviously thinks 
it is possible machine systems might some day "become" conscious. But how? How does a 
machine system "turn on subjectivity"?

((I know absence of knowledge of an answer is not evidence there is no answer. 
I am questioning not just whether there is an answer but whether the question even 
makes sense.))

Subjective awareness does not seem like something one can program. This means it 
would have to "emerge." But even then, how? This is where materialists simply resort 
to blind faith: humans evolved or emerged as conscious beings on Earth, why not 
machines?

There are two problems with this faith.

1. Human evolution is not a computation. It is physics. We do not *know* that physics is 
computation. It might not be. 
2. No one has any clue what they mean by "emergence." It's one of those buzzwords in so-
called 'complexity studies". It is meaningless.

On the first point, I have good reasons to suspect physics is definitely not 
computation. But that's partly because I regard inputs and initial boundary 
conditions *always* as part of a computation. This should *not* be controversial, 
it conforms with Turing's model.

(Von Neumann architecture is not a model of computation, Tring's model is. von 
Neumann designed a type of process do do something like a sub-Truing machine could 
do on paper, but the model was not a model of computation *per se*, it was the 
snow plough.)

Douglas did find CoPilot and Stable Diffusion incredibly useful. But I try to tell 
him that's his mind he a was using. The snow ploughs were not suggesting anything 
conscious was emerging. If Copilot did what I do --- which is anticipate Douglas' 
MacroTrader needs, and then slyly go and work on something even better, then I'd be 
willing to attribute the system some sentience.

If Douglas is prompting you, and that's all, you are not conscious, or if you are 
you're a slave.

On the second point: emergence. I've often thought about writing for a journal on this 
topic, but my ideas are too far from mainstream science t get published probably.

David Chalmers and others have done some ok work on defining categories of emergence, so 
they give you a start.

The problem is the big daddy of emergence: **_genuine emergence_** of novelty from 
beginning s or priors that make the emergent stuff not merely unpredictable, but 
impossible without a high-level description.  that is t say, the emergent system 
cannot even in principle be reduced to base physics.

But then what is is based upon?
It cannot be based upon physics. So it as to be "genuine" emergence. 
We could not build them from first principles.

If such systems exist, they're not physical. They're something we would not comprehend, 
perhaps we'd call them spiritual?  Perhaps we'd call them human?

However, we "build" humans all the time, with a bit of hanky panky in the bedrooms 
or wherever you get your kicks. It's kind of funny making babies is such a sweaty and 
emotional process. God must have a sense of humour.

As I like to say, there is no artificial intelligence. There's no genuine "AI" there 
is just "*_I_*."


[Next post (TBD)](./)  
[Previous post (True Populist)](../16_true_populism)   
[Back to Blog TOC](../)

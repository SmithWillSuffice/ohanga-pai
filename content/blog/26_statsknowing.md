---
title: "Statistical Knowing"
description: ""
date: 2023-05-10
lastmod: 2023-05-10
cover: ""
coverAlt: ""
toc: true
tags: []
katex: true
---

More criss-crossing with my philosophy of mind between the physics (over at 
[T4GU]( https://t4gu.gitlab.io/t4gu/)). Although I try to keep the economics 
implications stuff here at Ōhanga Pai, and the physics stuff over at T4GU, today I 
will hedge on where my readers go and point them here. Today is a special blog where 
I will start to record my staking of positions on what the recent artificial 
intelligence LLM models can and cannot do.

I rely on experts to help figure out how the models work, but also youtubers for 
breakdowns on what real users can do with the LLM's. Today I will start with this 
channel 
[“AI Explained” and the clip here](https://www.youtube.com/watch?v=4MGCQOAxgv4).  I 
know there are plenty more amazing uses which chatGPT is being put to, especially 
functional chaining, so I want to mention that too, I will start with this.

## AI Chains

Functional chaining is just a more algorithmic way of combining tools. When you can 
manipulate output of one program and fee it into another, then you have a whole 
ecosystem of programs.

UNIX programmers in the 1970's figured out the power of this methodology, and 
built system programs called pipes to make it dead simple of *nix programmers to 
chain simple programs together to do powerful overall tasks. They were forced to do 
so in one way because of limited disk memory back then, but it was also an entire 
philosophy of computing: 

> Do one thing well.

Every program should obey this rule, at least morally. Monolithic programs doing many 
things normally do nothing well, although when they run error free they can do a 
super complex thing pretty well. This is almost what current neural net AI models are 
doing. They by-pass the Nix philosophy and brute-force their way to barrage the CPU 
and GPU of the server machines (or you laptop) with instructions that carry out 
massive statistical analysis.

There is no "thinking" or sentience involved here, it is not the same as human 
perception. The AI language models, speech and image recognition programs are not 
designed to operate like humans, they are our antithesis. 

This is a bold claim and runs against mainstream AI research politics, where the 
paradigm is that humans just do the same statistical search as the machines.

The main reason we cna clearly see why the AI nerds are wrong is to look at the way 
human cognition evolved and develops --- so from our ancestors and in our children. 
This type of cognition is highly symbolic and platonic, and is effective with extreme 
poverty of inputs. It is not statistical in any sense, except when people think about 
statistics. Our brains are not using statistical processes that operate on large 
stores of data.

In fact neuroscientists and psychologists have no idea how brains form minds, it is 
still a complete mystery. 

Our brains seem to act far more holistically, building mental models on-the-fly 
almost, with very little relevant information and swamped by loads of sensory noise. 
The AI systems are the opposite, they need highly clean curated data to function 
well. 

However, there are similarities between AI and minds. There is an ecosystem in both 
cases. In humans we have culture, in machines they have function chaining.

The early AI enthusiasts were aware of how simple programs could combine to form 
complex systems, Marvin Minksy called it a Society of Mind.  It is the same idea has 
the old hard-nosed *nix programmers. 

Although one neural net LLLm model is a beast ---  doing far too many things poorly, but overall exploiting statistics to get the job done, they are trained upon curated cleaned data --- the latest generation of AI toolkits are combining various of these beasts into distributed systems that form primitive *Societies of AI*.

I would not call them Minds, because they lack subjective phenomenal qualia, but they are the machine analogs of general problem solvers (which is a crude way of characterising a thinking mind --- a behavioural description which lacks all subjectivity).

Although it is a simple idea, it is still pretty cool. The automation capacities of the LLM models and other tools like image and speech classifiers and synthesizers, means beastly programs are statistically in the end doing certain things pretty ok.
SO sticking them together in AI mash-ups is the society of AI. It promises some incredible general purpose systems.

My special plea is for AI researchers to target disable d people. They stnad to 
benefit more than any other segment of society from personal computers that can 
seamlessly and fairly error-free carry out instructions from speech in the way 
Trekkies and others have long hoped for, far more powerful than Amazon Alexa or 
Apple Siri or Google Assistant. o

The free software community should have such disability assistant programs out soon 
after the commercial tools. Then your personal computer really will be pretty 
personal. Say goodbye to awkward document readers and speech-to-text transcribers, 
and say hello to an integrated computer assistant that knows what you wnat to do next 
(90% of the time).

That is not mind reading, despite the AI nerd fever dreams. it is just statistical 
prediction. If I gaze into my own Crystal Ball, I can tell you, the Sun will rise in 
the East tomorrow, and I am going to eat a sandwich around noon. Please prepare it 
for me Kitchen RoboGPT. Oh, you already scheduled that? Ok, cancel it, I want fish & 
chips instead.





<table style="border-collapse: collapse; border=0;">
    <colgroup>
       <col span="1" style="width: 35%;">
       <col span="1" style="width: 15%;">
       <col span="1" style="width: 25%;">
    </colgroup>
<tr style="border: 1px solid color:#0f0f0f;">
<td style="border: 1px solid color:#0f0f0f;"><a href="../25_agi_fearandloathing">Previous chapter</a></td>
<td style="border: 1px solid color:#0f0f0f; text-align:center;"><a href="../">Back to Posts</a></td>
<td style="border: 1px solid color:#0f0f0f; text-align:right;"><a href="./">Next chapter</a></td>
</tr>
<tr style="border: 1px solid color:#0f0f0f;">
<td style="border: 1px solid color:#0f0f0f;"><a href="../25_agi_fearandloathing">Fear and Loathing of AI</a></td>
<td style="border: 1px solid color:#0f0f0f; text-align:center;"><a href="../">TOC</a></td>
<td style="border: 1px solid color:#0f0f0f; text-align:right;"><a href="./">(TBD)</a></td>
</tr>
</table>

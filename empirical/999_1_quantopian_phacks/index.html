<!doctype html><html lang=en data-mode=dark><head prefix="og: http://ogp.me/ns#"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.117.0"><meta name=theme content="Color Your World -- gitlab.com/rmaguiar/hugo-theme-color-your-world"><title>Quantopian Series Notes | Ōhanga Pai</title><meta name=author content="Bijou M. Smith"><meta name=robots content="index follow"><link rel=canonical href=https://smithwillsuffice.github.io/ohanga-pai/empirical/999_1_quantopian_phacks/><meta property="og:site_name" content="Ōhanga Pai"><meta property="og:title" content="Quantopian Series Notes"><meta property="og:url" content="https://smithwillsuffice.github.io/ohanga-pai/empirical/999_1_quantopian_phacks/"><meta property="og:type" content="website"><meta name=twitter:dnt content="on"><meta name=theme-color content="#222"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="default"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","url":"https://smithwillsuffice.github.io/ohanga-pai/","inLanguage":"en","name":"Ōhanga Pai","description":"Geon Theory Development","publisher":"Bijou M. Smith"}</script><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/css/main.min.d33233e3d0eb633ea1fbb9e17553fe7c8ff07875b91d8186e046a48480987c8e.css integrity="sha256-0zIz49DrYz6h+7nhdVP+fI/weHW5HYGG4EakhICYfI4=" crossorigin=anonymous><noscript><meta name=theme-color content="#1585d5"><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/css/noscript.min.d73d9c33b150230799106ddda48c6861047535f400bf9ad26ec48665cf803050.css integrity="sha256-1z2cM7FQIweZEG3dpIxoYQR1NfQAv5rSbsSGZc+AMFA=" crossorigin=anonymous></noscript><link rel=preload href=/ohanga-pai/fonts/OpenSans-Bold.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/OpenSans-Italic.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/OpenSans-Regular.ttf as=font crossorigin=anonymous><link rel=preload href=/ohanga-pai/fonts/Oswald-Bold.ttf as=font crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Main-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Math-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size2-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size4-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><script src=https://smithwillsuffice.github.io/ohanga-pai/js/main.eaf40cb85ba7b448519428d1b6c856258731f0bb71f875d541ba615cfca4bdbc.js integrity="sha256-6vQMuFuntEhRlCjRtshWJYcx8Ltx+HXVQbphXPykvbw=" crossorigin=anonymous></script></head><body><header><a href=/ohanga-pai><img src=https://smithwillsuffice.github.io/ohanga-pai/images/ohp_logo.svg alt="T4GU logo" style=display:flex;width:40px;height:34px;float:left;margin-bottom:-2.5px;margin-right:10px></a>
<a href=/ohanga-pai>Ōhanga Pai</a><nav aria-label="Main menu."><ul><li><a class=btn href=/ohanga-pai/>Home</a></li><li><a class=btn href=/ohanga-pai/questions/>Questions</a></li><li><a class=btn href=/ohanga-pai/empirical/>Empirical</a></li><li><a class=btn href=/ohanga-pai/blog/>Posts</a></li><li><a class=btn href=/ohanga-pai/contact/>Contact</a></li><li><a class=btn href=/ohanga-pai/donations/>Donate</a></li></ul></nav></header><div class=filler><main><article><header><h1>Quantopian Series Notes</h1><p>Published on <time datetime=2023-01-15>2023-01-15</time></p></header><details class=toc open><summary class=outline-dashed>Contents</summary><nav id=TableOfContents><ul><li><a href=#p-value-hacking>p-value Hacking</a><ul><li><a href=#terminology>Terminology</a></li></ul></li><li><a href=#using-p-values-in-hypothesis-testing>Using p-values in hypothesis testing</a><ul><li><a href=#best-practise>Best Practise</a></li><li><a href=#in-summary>In summary</a></li></ul></li></ul></nav></details><p>A few highlights from the
<a href=https://gist.github.com/ih2502mk/50d8f7feb614c8676383431b056f4291 target=_blank>Quantopian Series</a>
worth remembering for teaching. these will start off unordered, but after I write a half
dozen or so I will try to impose some loose pedagogical order. (That just means the
links will change, ok. So if referencing use the TOC and search box instead.)</p><h2 id=p-value-hacking><a class=anchor href=#p-value-hacking title='Anchor for: p-value Hacking.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>p-value Hacking</h2><p>Ref: <a href="https://www.youtube.com/watch?v=YiDfbYtgUPc" target=_blank>Quantopian Lecture Series: p-Hacking and Multiple Comparisons Bias</a>
.</p><h3 id=terminology><a class=anchor href=#terminology title='Anchor for: Terminology.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Terminology</h3><ul><li><strong>False positive</strong> &mdash; a test indicates presence of an effect when in reality an oracle would say there is no effect.</li><li><strong>False negative</strong> &mdash; a test indicates absence of an effect when in reality an oracle
would say there is an effect.</li><li>Think of the Null Hypothesis as the &ldquo;negative&rdquo; hypothesis (&ldquo;there is no effect&rdquo; or &ldquo;there is no discernable distinction&rdquo;).</li><li><strong>Multiple comparison bias</strong> &mdash; the more inferences that are made (e.g., estimated parameters) without sample consideration corrections, the more likely are errors in other inferences based upon the former.</li></ul><h2 id=using-p-values-in-hypothesis-testing><a class=anchor href=#using-p-values-in-hypothesis-testing title='Anchor for: Using p-values in hypothesis testing.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Using p-values in hypothesis testing</h2><p>In statistics you want to minimize both FP and FN, but if there is a tension in use
of your resources you will probably want to minimize risk of getting false positives
more than the risk of getting false negatives. (But this can depend upon context.) For
example, in medical drug trials (a dodgy area of application) the default has to be
&ldquo;not release the drug&rdquo; so you certainly want the bias to be for false negatives
rather than false positives. A false positive is a bias towards releasing a drug
(with possible side-effects) that is in fact a useless drug, maybe harmful in other
ways.</p><p>A false negative is a bias towards not releasing a drug that would have had benefits.
You never know the oracle of course, but you at least should know the odds.</p><p>$p$-values in hypothesis testing assume a lot! One is a distribution of the score of
&ldquo;fitness&rdquo; (which could be a $t$-test, an $F$ score, a $\chi^2$ score, et cetera) the
$p$-value is a probability &mdash; <em><strong>but</strong> you do <strong>not</strong> want to <strong>use</strong> it as a
probability</em>!!!!</p><ul><li>Decide on what the qualitative and quantitative value of the test outcome is for you.
For high risk choose a very &ldquo;low significance&rdquo; (say 1% or less).</li><li>A significance level of 1% is a <em>high chance</em> 99% (assuming a bunch of stuff) of
getting a true negative (NullHyp is oracle true & the test indicates it is true) or a false negative (NullHyp is oracle false & the test indicates it is true)&mldr;</li><li>&mldr; and a low chance (1%) of getting a false positive (NullHyp is oracle true & the test indicates it is false).</li></ul><p>These interpretations of $p$-values are terrible dicey though:</p><ul><li>These are not absolute probabilities, they&rsquo;re conditional &mdash; they are
probabilities only <em>given</em> the assumptions of the model are correct (and
Gaussian errors, whatever else the test statistic assumes, etc.)</li><li>If you are in social sciences you might tolerate more false negatives (NullHyp is true
& the test indicates it is false) but only as the cost for the pay-off of decreasing
your rate of false positives.</li><li>For a lot of problems the more hazardous (in real life terms) outcome is a false
positive (NullHyp is true & test indicates it is false) &mdash; this is because a true
NullHyp is &ldquo;There is no effect&rdquo;, so a false positive is going to bias you towards
thinking there is an effect when according to a putative oracle there is none.</li></ul><p>A better way perhaps to remember what the $p$-value is, is that it is simply
the probability of getting a worse test statistic than what you observed,
where &ldquo;worse&rdquo; is worse than what the NullHyp being true would imply.</p><p>The way you then <em><strong>use</strong></em> the $p$-value is as a criterion for rejecting or accepting
the NullHyp, you will not use the $p$-value <em>as</em> a probability, even though it is a
conditional probability. You instead pre-choose a significance level <em>appropriate for
your data + model context</em>. Then use the $p$-value as a cut-off.</p><p>Emphasis is on <em>your</em> choice! Emphasis on that it is Bayesian (<strong>given</strong> the NullHyp is true).</p><h3 id=best-practise><a class=anchor href=#best-practise title='Anchor for: Best Practise.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Best Practise</h3><p><strong>Best practice</strong> is thus to figure out what a <em>sensible</em> significance level
is <em>first</em>. Then in your code do <em>not</em> print out the $p$-value, instead print out
<em>only</em>, either</p><p><strong>(1)</strong> &ldquo;no significant relationship indicated.&rdquo;<br>    or<br><strong>(2)</strong> &ldquo;a significant relationship is indicated.&rdquo;<br>    or<br><strong>(3)</strong> &ldquo;the test is inconclusive.&rdquo;</p><p>(because language framing matters for non-meathead beings.)</p><p>Also print the significance level you chose as a reminder, it gives the meaning to the
word &ldquo;significance&rdquo;. This takes eyes off the $p$-value, which is what you want for
people reading your research. It is fine to look at the $p$-value to worry about
things like sample size biases, desire to repeat a trial, and whatnot (the
meta-statistics stuff).</p><p>But how would you &ldquo;know&rdquo; the test is inconclusive? Because a significance level
cut-off (5% or whatever) is a binary distinction, so you&rsquo;d only have the first two
output statements coded.</p><p><strong>Better practice?</strong> I would not choose one single cut-off, but a worst case and best
case, so a range of significance levels. Ex. for extreme risk analysis maybe you want
worst case acceptance of a false positive to be 0.01% (which is getting more like the
6-sigma level for particle physics research); and best case to be even more
stringent, like 0.001%.</p><p><em>Alright!</em> Now in your code you can print out the third statement above, whenever the
measured statistic yields a $p$-value in between your best and worst case significances.</p><p>If you are in social sciences those significance levels would be a bit absurd, you&rsquo;d
get too many false negatives (accepting NullHyp when the oracle would say it is false).
But like we said, depending upon context that can often be better than more chance of
false positives (rejecting NullHyp when the oracle would say it is true).</p><p>Always remember, a $p$-value test is highly dependent upon your choice of
significance level. It is a cut-off encoding your knowledge of a situation or context,
it is not a machine telling you what the real world is like.</p><p>Before summarizing, one other point: <strong>Multiple comparison bias</strong> is not a thing in
statistics, it is a mistake of mere mortals. You would never have such bias if you
understood the statistics, you would always be making the appropriate corrections,
which is the study of uncertainty and error propagation.</p><p>On very basic correction is the
<a href=https://en.wikipedia.org/wiki/Bonferroni_correction target=_blank>Bon-Ferroni Correction</a>
which the Quantopian <a href="https://youtu.be/YiDfbYtgUPc?t=1694" target=_blank>explains here</a>
but we can state it in one sentence:</p><blockquote><p>Bon-Ferroni correction: if you use $m$ tests, in each use a significance level of
$\alpha/m$ where $\alpha$ is your overall desired significance. You then should
expect a fraction $\alpha$ of the tests pass, and $(1-\alpha)$ fail.</p></blockquote><p>In this way the false positive rate when taking <em>all</em> the $m$ tests together is
back to $\alpha$. If that&rsquo;s not the case within reasonable uncertainties then your model (or data) needs updating).</p><p>The Quantopian <a href="https://www.youtube.com/watch?v=YiDfbYtgUPc0" target=_blank>lecture on p-hacking and multiple comparisons bias</a>
is a good overview of this topic, with a few tips for people who are at risk of
over-using neural networks and whatnot. A lecture is only as good though as the
student is willing to take heed. In a dog-eat-dog world and rat-race people are prone
to taking short-cuts and skipping the grind of testing. So just do not say you were
never warned.</p><p><em>Do the <strong>out-of-sample testing</strong> my dudes.</em> If you have the need to make it fun,
use it to prank your colleagues. (Fudge their data, yo! Just don&rsquo;t forget to tell
them afterwards.)</p><h3 id=in-summary><a class=anchor href=#in-summary title='Anchor for: In summary.'><svg aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>In summary</h3><p>Figure out what a <em>sensible</em> significance level range is <em>first</em> using your
domain expert knowledge.
Then in your code do not print out the $p$-value, instead print out only, either</p><p><strong>(1)</strong> &ldquo;no significant relationship indicated.&rdquo;<br>    or<br><strong>(2)</strong> &ldquo;a significant relationship is indicated.&rdquo;<br>    or<br><strong>(3)</strong> &ldquo;the test is inconclusive.&rdquo;</p><p><strong>Further TODO:</strong> a $p$-value hypothesis test can be useful when you are in
<em>Moderatistan</em> (Gaussians) but could be highly misleading if your underlying data
source is fat-tailed. If you are dealing with fat-tails (first test for them using
maximum values) and consider using a different type of hypothesis test, e.g., one
that scores maximum values, not the medians or means.</p><p><a href=./>Next chapter (TBD)</a><br><a href=../99_macro_trader>Previous chapter (Macro Trading-1)</a><br><a href=../>Back to Empirical Pages</a></p></article></main></div><footer><div class=req-js><button class=outline-dashed title="Change to light/dark mode."><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true"><use xlink:href="/ohanga-pai/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#adjust"/></svg></button><input class=outline-dashed type=color list=presets value=#1585d5 title="Change accent color." aria-label="Change accent color."><datalist id=presets><option value=#1f676b><option value=#1585d5><option value=#225670><option value=#dd587c><option value=#902b37><option value=#f3a530><option value=#754e85><option value=#7fc121><option value=#a8314a><option value=#ff7433><option value=#3e6728><option value=#c063bd><option value=#805080><option value=#9d629d><option value=#a064a0><option value=#7daa50><option value=#284531><option value=#285790><option value=#F5A83D><option value=#88aa33><option value=#015660><option value=#bf274e><option value=#bf4242><option value=#51b37c></datalist></div><noscript><p class=noscript>Unable to execute JavaScript. Some features were disabled.</p></noscript></footer><link rel=stylesheet href=https://smithwillsuffice.github.io/ohanga-pai/libs/katex@0.16.0/dist/katex.min.6950e59dbd8dfddd111390d85888bb5f9dc2e9c334da7ac1c3bacc92a695610d.css integrity="sha256-aVDlnb2N/d0RE5DYWIi7X53C6cM02nrBw7rMkqaVYQ0=" crossorigin=anonymous><script defer src=https://smithwillsuffice.github.io/ohanga-pai/libs/katex@0.16.0/dist/katex.min.5e5e5e3f11510a5488490612ff5c36a48c133ae81bb9d2e4e5c377309de5ece2.js integrity="sha256-Xl5ePxFRClSISQYS/1w2pIwTOugbudLk5cN3MJ3l7OI=" crossorigin=anonymous></script>
<script defer src=https://smithwillsuffice.github.io/ohanga-pai/js/katex-custom-render.min.cdeaf561a454e015b169c385f95c72d57d41f906a9bc4100636b18e1e4c15da3.js integrity="sha256-zer1YaRU4BWxacOF+Vxy1X1B+QapvEEAY2sY4eTBXaM=" crossorigin=anonymous></script></body></html>